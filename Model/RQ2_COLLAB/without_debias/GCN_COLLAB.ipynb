{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42745,"status":"ok","timestamp":1687256889665,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"xVEXjGk1WGRp","outputId":"fe27a356-5f87-4f82-be26-5aa90a5f06c4"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu118\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting pyg_lib\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (205 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n","Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n","Successfully installed pyg_lib-0.2.0+pt20cpu torch_cluster-1.6.1+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu torch_spline_conv-1.2.2+pt20cpu\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement warnings (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for warnings\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dgl\n","  Downloading dgl-1.1.0-cp310-cp310-manylinux1_x86_64.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n","Installing collected packages: dgl\n","Successfully installed dgl-1.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting texttable\n","  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n","Installing collected packages: texttable\n","Successfully installed texttable-1.6.7\n","cpu\n"]}],"source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install warnings\n","!pip install dgl\n","!pip install texttable\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1684407110585,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"dq-Zd6aQWRvb","outputId":"c2fb6ea6-1666-4ca4-edd3-c86a7115042f"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cGqoLa84WV7k"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":888,"status":"ok","timestamp":1687256890548,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"LtHqVCYeNmmv","outputId":"503abd72-e61a-4a3b-b29b-e2c5a414b307"},"outputs":[{"name":"stderr","output_type":"stream","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"name":"stdout","output_type":"stream","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["import random\n","from torchvision import transforms, datasets\n","\n","import os\n","import pickle\n","from scipy.spatial.distance import cdist\n","from scipy import ndimage\n","import numpy as np\n","\n","import dgl\n","import torch\n","import time\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import matplotlib\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2101,"status":"ok","timestamp":1687256892646,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"Q2RkYPa8k9nE"},"outputs":[],"source":["import torch\n","from torch.nn import Parameter\n","from torch_scatter import scatter_add\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n","from torch_geometric.nn.inits import glorot, zeros\n","import pdb\n","\n","\n","class GCNConv(MessagePassing):\n","\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 improved=False,\n","                 cached=False,\n","                 bias=True,\n","                 edge_norm=True,\n","                 gfn=False):\n","        super(GCNConv, self).__init__('add')\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.improved = improved\n","        self.cached = cached\n","        self.cached_result = None\n","        self.edge_norm = edge_norm\n","        self.gfn = gfn\n","        self.message_mask = None\n","        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n","\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.weight)\n","        zeros(self.bias)\n","        self.cached_result = None\n","\n","    @staticmethod\n","    def norm(edge_index, num_nodes, edge_weight, improved=False, dtype=None):\n","        if edge_weight is None:\n","            edge_weight = torch.ones((edge_index.size(1), ),\n","                                     dtype=dtype,\n","                                     device=edge_index.device)\n","\n","        edge_weight = edge_weight.view(-1)\n","\n","\n","        assert edge_weight.size(0) == edge_index.size(1)\n","\n","        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n","        edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n","        # Add edge_weight for loop edges.\n","        loop_weight = torch.full((num_nodes, ),\n","                                 1 if not improved else 2,\n","                                 dtype=edge_weight.dtype,\n","                                 device=edge_weight.device)\n","        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)\n","\n","        row, col = edge_index\n","        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","\n","        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        \"\"\"\"\"\"\n","\n","        x = torch.matmul(x, self.weight)\n","        if self.gfn:\n","            return x\n","\n","        if not self.cached or self.cached_result is None:\n","            if self.edge_norm:\n","                edge_index, norm = GCNConv.norm(\n","                    edge_index,\n","                    x.size(0),\n","                    edge_weight,\n","                    self.improved,\n","                    x.dtype)\n","            else:\n","                norm = None\n","            self.cached_result = edge_index, norm\n","\n","        edge_index, norm = self.cached_result\n","        return self.propagate(edge_index, x=x, norm=norm)\n","\n","    def message(self, x_j, norm):\n","\n","        if self.edge_norm:\n","            return norm.view(-1, 1) * x_j\n","        else:\n","            return x_j\n","\n","    def update(self, aggr_out):\n","        if self.bias is not None:\n","            aggr_out = aggr_out + self.bias\n","        return aggr_out\n","\n","    def __repr__(self):\n","        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n","                                   self.out_channels)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687256892648,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"jCXZmqIT4gvJ"},"outputs":[],"source":["from functools import partial\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Linear, BatchNorm1d, Sequential, ReLU\n","from torch_geometric.nn import global_mean_pool, global_add_pool, GINConv, GATConv\n","\n","import random\n","import pdb\n","device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","\n","layers=3\n","with_random=True\n","fc_num=222\n","hidden=32\n","eval_random=False\n","class GCNNet(torch.nn.Module):\n","    \"\"\"GCN with BN and residual connection.\"\"\"\n","    def __init__(self, num_features,\n","                       num_classes, hidden=32,\n","                       num_feat_layers=1,\n","                       num_conv_layers=3,\n","                 num_fc_layers=2, gfn=False, collapse=False, residual=False,\n","                 res_branch=\"BNConvReLU\", global_pool=\"sum\", dropout=0,\n","                 edge_norm=True):\n","        super(GCNNet, self).__init__()\n","\n","        self.global_pool = global_add_pool\n","        self.dropout = dropout\n","        GConv = partial(GCNConv, edge_norm=edge_norm, gfn=gfn)\n","\n","        hidden_in = num_features\n","        self.bn_feat = BatchNorm1d(hidden_in)\n","        self.conv_feat = GCNConv(hidden_in, hidden, gfn=True) # linear transform\n","        self.bns_conv = torch.nn.ModuleList()\n","        self.convs = torch.nn.ModuleList()\n","\n","        for i in range(num_conv_layers):\n","            self.bns_conv.append(BatchNorm1d(hidden))\n","            self.convs.append(GConv(hidden, hidden))\n","        self.bn_hidden = BatchNorm1d(hidden)\n","        self.bns_fc = torch.nn.ModuleList()\n","        self.lins = torch.nn.ModuleList()\n","\n","        for i in range(num_fc_layers - 1):\n","            self.bns_fc.append(BatchNorm1d(hidden))\n","            self.lins.append(Linear(hidden, hidden))\n","        self.lin_class = Linear(hidden, num_classes)\n","\n","        # BN initialization.\n","        for m in self.modules():\n","            if isinstance(m, (torch.nn.BatchNorm1d)):\n","                torch.nn.init.constant_(m.weight, 1)\n","                torch.nn.init.constant_(m.bias, 0.0001)\n","\n","    def forward(self, data):\n","\n","        x = data.x if data.x is not None else data.feat\n","        edge_index, batch = data.edge_index, data.batch\n","\n","        x = self.bn_feat(x)\n","        x = F.relu(self.conv_feat(x, edge_index))\n","\n","        for i, conv in enumerate(self.convs):\n","            x = self.bns_conv[i](x)\n","            x = F.relu(conv(x, edge_index))\n","\n","        x = self.global_pool(x, batch)\n","        for i, lin in enumerate(self.lins):\n","            x = self.bns_fc[i](x)\n","            x = F.relu(lin(x))\n","\n","        x = self.bn_hidden(x)\n","        x = self.lin_class(x)\n","        return F.log_softmax(x, dim=-1)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1687256892649,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"85yBn66PB_QG"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch_geometric.data import DataLoader, DenseDataLoader as DenseLoader\n","from torch import tensor\n","import torch_geometric.transforms as T\n","from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n","import pdb\n","import random\n","import numpy as np\n","from torch.autograd import grad\n","from torch_geometric.data import Batch\n","import networkx as nx\n","from torch_geometric.utils import to_networkx\n","\n","\n","def generate_node_feature(data):\n","  G = to_networkx(data, to_undirected=True) # Convert to networkx graph\n","\n","  # Calculate eigenvector centrality\n","  centrality = nx.eigenvector_centrality_numpy(G)\n","\n","  # Convert the centrality dictionary to a list maintaining the order of nodes\n","  node_features = [centrality[node] for node in G.nodes]\n","\n","  # Convert to tensor\n","  node_features=torch.tensor(node_features, dtype=torch.float).view(-1, 1)\n","\n","  return node_features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ewtiaFv7H4AC","outputId":"a6f70be8-0327-4462-c549-bd7d7c25f055"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: COLLAB(5000):\n","======================\n","Number of graphs: 5000\n","Number of features: 0\n","Number of classes: 3\n","\n","First graph in the dataset:\n","======================\n","Number of nodes: 52\n","Number of edges: 2188\n","Average node degree: 42.08\n","Contains isolated nodes: No\n","Contains self-loops: No\n","Is undirected: Yes\n","training size:3500\n","valating size:750\n","testing size:750\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_isolated_nodes' is deprecated, use 'has_isolated_nodes' instead\n","  warnings.warn(out)\n","/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'contains_self_loops' is deprecated, use 'has_self_loops' instead\n","  warnings.warn(out)\n"]}],"source":["from torch_geometric.datasets import TUDataset\n","import os.path as osp\n","from torch.utils.data import random_split\n","from torch_geometric.datasets import TUDataset\n","path ='/content/drive/MyDrive/'\n","# Load the COLLAB dataset\n","dataset = TUDataset(root='/content/drive/MyDrive/', name='COLLAB')\n","\n","# Print some information about the dataset\n","print(f'Dataset: {dataset}:')\n","print('======================')\n","print(f'Number of graphs: {len(dataset)}')\n","print(f'Number of features: {dataset.num_features}')\n","print(f'Number of classes: {dataset.num_classes}')\n","\n","# Print information about the first graph in the dataset\n","data = dataset[1]\n","print('\\nFirst graph in the dataset:')\n","print('======================')\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Contains isolated nodes: {\"Yes\" if data.contains_isolated_nodes() else \"No\"}')\n","print(f'Contains self-loops: {\"Yes\" if data.contains_self_loops() else \"No\"}')\n","print(f'Is undirected: {\"Yes\" if data.is_undirected() else \"No\"}')\n","\n","train_size = int(len(dataset) * 0.7)\n","val_size = int(len(dataset) * 0.15)\n","test_size = len(dataset) - train_size - val_size\n","print(f'training size:{train_size}')\n","print(f'valating size:{val_size}')\n","print(f'testing size:{test_size}')\n","\n","# Generate the splits\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n","training=[]\n","valating=[]\n","testing=[]\n","for data in train_dataset:\n","  data.x=generate_node_feature(data)\n","  training.append(data)\n","for data in val_dataset:\n","  data.x=generate_node_feature(data)\n","  valating.append(data)\n","for data in test_dataset:\n","  data.x=generate_node_feature(data)\n","  testing.append(data)\n","print(f'training size:{len(training)}')\n","print(f'valating size:{len(valating)}')\n","print(f'testing size:{len(testing)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMIKg4G_le-T"},"outputs":[],"source":["train_loader = DataLoader(training, batch_size=32, shuffle=True)\n","val_loader = DataLoader(valating, batch_size=32, shuffle=False)\n","test_loader = DataLoader(testing, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqj2r-DqOxaT"},"outputs":[],"source":["number_of_class=3\n","Epo=500\n","model= GCNNet(1,number_of_class).to(device)\n","\n","optimizer = Adam(model.parameters(), lr=0.001)\n","lr_scheduler = CosineAnnealingLR(optimizer, T_max=Epo, eta_min=1e-6, last_epoch=-1, verbose=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvidGrhFBdK4"},"outputs":[],"source":["import time\n","import json\n","\n","loss_value=[]\n","loss_value_valation=[]\n","\n","def num_graphs(data):\n","  if data.batch is not None:\n","      return data.num_graphs\n","  else:\n","      return data.x.size(0)\n","from tqdm import tqdm\n","\n","for epoch in range(Epo):\n","  model.train()\n","  total_loss = 0\n","  correct = 0\n","  nb=0\n","  print(f\"-----training-------{epoch}\")\n","  loop = tqdm(enumerate(train_loader),total=len(train_loader))\n","  for it, data in loop:\n","#  for it, data in enumerate(train_loader):\n","      nb+=1\n","      optimizer.zero_grad()\n","      data = data.to(device)\n","      out = model(data)\n","      loss = F.nll_loss(out, data.y.view(-1))\n","      pred = out.max(1)[1]\n","      correct += pred.eq(data.y.view(-1)).sum().item()\n","      loss.backward()\n","      total_loss += loss.item() #* num_graphs(data)\n","      optimizer.step()\n","      loop.set_description(f\"Epoch [{epoch}/{Epo}]\")\n","      loop.set_postfix(loss = loss.item())\n","\n","  #num = len(train_loader.dataset)\n","  total_loss = total_loss / nb\n","  lr_scheduler.step()\n","\n","  print(f'number of {epoch} with total loss:{total_loss}')\n","  loss_value.append(total_loss)\n","  correct = correct / nb\n","  with torch.no_grad():\n","    model.eval()\n","    correct = 0\n","    print(f\"------valation---------{epoch}\")\n","    for data in test_loader:\n","      data = data.to(device)\n","      pred = model(data).max(1)[1]\n","      correct += pred.eq(data.y.view(-1)).sum().item()\n","    acc_o = correct / len(test_loader.dataset)\n","    print(f\"causal val accuracy:{acc_o}\")\n","    loss_value_valation.append(acc_o)\n","    dictionary={\"number of epoch\":epoch,\n","                \"training loss list\":loss_value,\n","                \"valation accuracy list\":loss_value_valation}\n","\n","    # Serializing json\n","    json_object = json.dumps(dictionary,indent=3)\n","\n","    # Writing to sample.json\n","    with open(\"/content/drive/MyDrive/running_RQ2/COLLAB/GCN_collab.json\", \"w\") as outfile:\n","        outfile.write(json_object)\n","\n","    #torch.save(causal_model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/430cau_my6000.pt')\n","    #torch.save(predictco_model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/430caupred_my6000.pt')\n","    #torch.save(predictno_model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/430noncaupred_my6000.pt')\n","    #torch.save(model_heter.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/430heter6000.pt')\n","    torch.save({\n","            'GCN_model.state_dic': model.state_dict(),\n","            'opt':optimizer.state_dict()\n","            }, '/content/drive/MyDrive/running_RQ2/COLLAB/GCNmodel_collab.pt')\n","    if(epoch>50):\n","      check=abs(acc_o-loss_value_valation[len(loss_value_valation)-20])/20\n","      if(check<=0.001):\n","        break\n","\n","\n","  #model_optimizer.zero_grad()\n","  #total_loss.backward()\n","  #model_optimizer.step()\n","\n","model.eval()\n","correct = 0\n","print(f\"------test---------{00}\")\n","for data in val_loader:\n","  data = data.to(device)\n","  pred = model(data).max(1)[1]\n","  correct += pred.eq(data.y.view(-1)).sum().item()\n","acc_o = correct / len(val_loader.dataset)\n","print(f\"causal val accuracy:{acc_o}\")\n","dictionary={\"number of epoch\":epoch,\n","        \"training loss list\":loss_value,\n","        \"valation accuracy list\":loss_value_valation,\n","        \"test accuracy value\":acc_o}\n","\n","# Serializing json\n","json_object = json.dumps(dictionary,indent=4)\n","\n","# Writing to sample.json\n","with open(\"/content/drive/MyDrive/running_RQ2/COLLAB/GCN_collab.json\", \"w\") as outfile:\n","  outfile.write(json_object)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPwOriNkRmZ3mR7idQ9lrwa","machine_shape":"hm","mount_file_id":"1YbnExC24FohoYONWFgi3toGftPH29cw7","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
