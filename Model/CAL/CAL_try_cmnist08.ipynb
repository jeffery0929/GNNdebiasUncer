{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41316,"status":"ok","timestamp":1687075564834,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"lqthoR-BkqIY","outputId":"66c590e6-9310-4b03-c010-58d88acc6b56"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.0.1+cu118\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","Collecting pyg_lib\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/pyg_lib-0.2.0%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (627 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m627.0/627.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_scatter\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (504 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.1/504.1 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_sparse\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.17%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_cluster\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.1%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (732 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.3/732.3 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_spline_conv\n","  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp310-cp310-linux_x86_64.whl (205 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.7/205.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.10.1)\n","Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.22.4)\n","Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n","Successfully installed pyg_lib-0.2.0+pt20cpu torch_cluster-1.6.1+pt20cpu torch_scatter-2.1.1+pt20cpu torch_sparse-0.6.17+pt20cpu torch_spline_conv-1.2.2+pt20cpu\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\u001b[31mERROR: Could not find a version that satisfies the requirement warnings (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for warnings\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dgl\n","  Downloading dgl-1.1.0-cp310-cp310-manylinux1_x86_64.whl (5.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n","Installing collected packages: dgl\n","Successfully installed dgl-1.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting texttable\n","  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n","Installing collected packages: texttable\n","Successfully installed texttable-1.6.7\n","cpu\n"]}],"source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install warnings\n","!pip install dgl\n","!pip install texttable\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","else:\n","  device = torch.device(\"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1686896908551,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"ngQLW0HJxnqY","outputId":"aa1b02fe-2312-4b2b-ca65-e2212c9ee525"},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35275,"status":"ok","timestamp":1687075600103,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"LtHqVCYeNmmv","outputId":"4f2f0440-a8a2-4550-bdb0-994a4d4a335b"},"outputs":[{"name":"stderr","output_type":"stream","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"name":"stdout","output_type":"stream","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}],"source":["import random\n","from torchvision import transforms, datasets\n","\n","import os\n","import pickle\n","from scipy.spatial.distance import cdist\n","from scipy import ndimage\n","import numpy as np\n","\n","import dgl\n","import torch\n","import time\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import matplotlib\n","def sigma(dists, kth=8):\n","    # Get k-nearest neighbors for each node\n","    knns = np.partition(dists, kth, axis=-1)[:, kth::-1]\n","\n","    # Compute sigma and reshape\n","    sigma = knns.sum(axis=1).reshape((knns.shape[0], 1))/kth\n","    return sigma + 1e-8 # adding epsilon to avoid zero value of sigma\n","\n","def compute_adjacency_matrix_images(coord, feat, use_feat=False, kth=8):\n","    coord = coord.reshape(-1, 2)\n","    # Compute coordinate distance\n","    c_dist = cdist(coord, coord)\n","\n","    if use_feat:\n","        # Compute feature distance\n","        f_dist = cdist(feat, feat)\n","        # Compute adjacency\n","        A = np.exp(- (c_dist/sigma(c_dist))**2 - (f_dist/sigma(f_dist))**2 )\n","    else:\n","        A = np.exp(- (c_dist/sigma(c_dist))**2)\n","\n","    # Convert to symmetric matrix\n","    A = 0.5 * A * A.T\n","    A[np.diag_indices_from(A)] = 0\n","    return A\n","\n","def compute_edges_list(A, kth=8+1):\n","    # Get k-similar neighbor indices for each node\n","    if 1==1:\n","        num_nodes = A.shape[0]\n","        new_kth = num_nodes - kth\n","        knns = np.argpartition(A, new_kth-1, axis=-1)[:, new_kth:-1]\n","        knns_d = np.partition(A, new_kth-1, axis=-1)[:, new_kth:-1]\n","    else:\n","        knns = np.argpartition(A, kth, axis=-1)[:, kth::-1]\n","        knns_d = np.partition(A, kth, axis=-1)[:, kth::-1]\n","    return knns, knns_d\n","class newCIFARSuperPix(torch.utils.data.Dataset):\n","    def __init__(self,\n","                 data_dir,\n","                 use_mean_px=True,\n","                 use_coord=True,\n","                 use_feat_for_graph_construct=False,):\n","\n","        #self.split = split\n","        #self.is_test = split.lower() in ['test', 'val']\n","        with open(data_dir, 'rb') as f:\n","            self.labels, self.sp_data = pickle.load(f)\n","\n","        self.use_mean_px = use_mean_px\n","        self.use_feat_for_graph = use_feat_for_graph_construct\n","        self.use_coord = use_coord\n","        self.n_samples = len(self.labels)\n","        self.img_size = 32\n","\n","    def precompute_graph_images(self):\n","        #print('precompute all data for the %s set...' % self.split.upper())\n","        self.Adj_matrices, self.node_features, self.edges_lists = [], [], []\n","        for index, sample in enumerate(self.sp_data):\n","            mean_px, coord = sample[:2]\n","            coord = coord / self.img_size\n","            A = compute_adjacency_matrix_images(coord, mean_px, use_feat=self.use_feat_for_graph)\n","            edges_list, _ = compute_edges_list(A)\n","            N_nodes = A.shape[0]\n","\n","            x = None\n","            if self.use_mean_px:\n","                x = mean_px.reshape(N_nodes, -1)\n","            if self.use_coord:\n","                coord = coord.reshape(N_nodes, 2)\n","                if self.use_mean_px:\n","                    x = np.concatenate((x, coord), axis=1)\n","                else:\n","                    x = coord\n","            if x is None:\n","                x = np.ones(N_nodes, 1)  # dummy features\n","\n","            self.node_features.append(x)\n","            self.Adj_matrices.append(A)\n","            self.edges_lists.append(edges_list)\n","\n","    def __len__(self):\n","        return self.n_samples\n","\n","    def __getitem__(self, index):\n","        g = dgl.DGLGraph()\n","        g.add_nodes(self.node_features[index].shape[0])\n","        g.ndata['feat'] = torch.Tensor(self.node_features[index])\n","        for src, dsts in enumerate(self.edges_lists[index]):\n","            g.add_edges(src, dsts[dsts!=src])\n","\n","        return g, self.labels[index]\n","\n","use_feat_for_graph_construct = False\n","tt = time.time()\n","data_with_feat_knn = newCIFARSuperPix(\"/content/drive/MyDrive/CMINST_data/CMNIST08_60000_75sp_train.pkl\",use_feat_for_graph_construct=use_feat_for_graph_construct)\n","\n","data_with_feat_knn.precompute_graph_images()\n","training_data = np.load('/content/drive/MyDrive/CMINST_data/colorMNIST08_60000_data.npy')\n","training_label=np.load('/content/drive/MyDrive/CMINST_data/colorMNIST08_60000_label.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0eqa0s54oKO"},"outputs":[],"source":["import numpy as np\n","import os.path as osp\n","import pickle\n","import torch\n","import torch.utils\n","import torch.utils.data\n","import torch.nn.functional as F\n","from scipy.spatial.distance import cdist\n","from torch_geometric.utils import dense_to_sparse\n","from torch_geometric.data import InMemoryDataset,Data\n","#/content/drive/MyDrive/Colab_Notebooks/mnist08_83_75sp_train.pkl\n","def compute_adjacency_matrix_images(coord, sigma=0.1):\n","    coord = coord.reshape(-1, 2)\n","    dist = cdist(coord, coord)\n","    A = np.exp(- dist / (sigma * np.pi) ** 2)\n","    A[np.diag_indices_from(A)] = 0\n","    return A\n","\n","\n","def list_to_torch(data):\n","    for i in range(len(data)):\n","        if data[i] is None:\n","            continue\n","        elif isinstance(data[i], np.ndarray):\n","            if data[i].dtype == np.bool:\n","                data[i] = data[i].astype(np.float32)\n","            data[i] = torch.from_numpy(data[i]).float()\n","        elif isinstance(data[i], list):\n","            data[i] = list_to_torch(data[i])\n","    return data\n","def process(data_file):\n","  use_mean_px=True\n","  use_coord=True\n","  node_gt_att_threshold=0\n","  transform=None\n","  pre_transform=None\n","  pre_filter=None\n","\n","  #data_file ='/content/drive/MyDrive/Colab_Notebooks/colorMNIST05_2000_75sp_train.pkl'\n","\n","  with open(osp.join(data_file), 'rb') as f:\n","      labels,sp_data = pickle.load(f)\n","\n","  #use_mean_px = self.use_mean_px\n","  #self.use_coord = self.use_coord\n","  n_samples = len(labels)\n","  img_size = 32\n","  #node_gt_att_threshold = self.node_gt_att_threshold\n","\n","  edge_indices,xs,edge_attrs,node_gt_atts,edge_gt_atts = [], [], [], [], []\n","  data_list = []\n","  for index, sample in enumerate(sp_data):\n","      mean_px, coord = sample[:2]\n","      coord = coord / img_size\n","      A = compute_adjacency_matrix_images(coord)\n","      N_nodes = A.shape[0]\n","\n","      A = torch.FloatTensor((A > 0.1) * A)\n","      edge_index, edge_attr = dense_to_sparse(A)\n","\n","      x = None\n","      if use_mean_px:\n","          x = mean_px.reshape(N_nodes, -1)\n","      if use_coord:\n","          coord = coord.reshape(N_nodes, 2)\n","          if use_mean_px:\n","              x = np.concatenate((x, coord), axis=1)\n","          else:\n","              x = coord\n","      if x is None:\n","          x = np.ones(N_nodes, 1)  # dummy features\n","\n","      # replicate features to make it possible to test on colored images\n","      x = np.pad(x, ((0, 0), (2, 0)), 'edge')\n","      if node_gt_att_threshold == 0:\n","          node_gt_att = (mean_px > 0).astype(np.float32)\n","      else:\n","          node_gt_att = mean_px.copy()\n","          node_gt_att[node_gt_att < node_gt_att_threshold] = 0\n","\n","      node_gt_att = torch.LongTensor(node_gt_att).view(-1)\n","      row, col = edge_index\n","      edge_gt_att = torch.LongTensor(node_gt_att[row] * node_gt_att[col]).view(-1)\n","\n","      data_list.append(\n","          Data(\n","              x=torch.tensor(x),\n","              y=torch.LongTensor([labels[index]]),\n","              edge_index=edge_index,\n","              edge_attr=edge_attr,\n","              node_gt_att=node_gt_att,\n","              edge_gt_att=edge_gt_att\n","\n","          )\n","      )\n","\n","  #torch.save(InMemoryDataset.collate(data_list), '/content/drive/MyDrive/Colab_Notebooks/colorMINST05_2000.pt')\n","  return data_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrQnfDYkxdR7"},"outputs":[],"source":["train_dir='/content/drive/MyDrive/CMINST_data/CMNIST095_10000_75sp_train.pkl'\n","val_dir='/content/drive/MyDrive/CMINST_data/CMNIST5000_75sp_val.pkl'\n","test_dir='/content/drive/MyDrive/CMINST_data/CMNIST10000_75sp_test.pkl'\n","training_final=process(data_file=train_dir)\n","valing_final=process(data_file=val_dir)\n","testing_final=process(data_file=test_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q2RkYPa8k9nE"},"outputs":[],"source":["import torch\n","from torch.nn import Parameter\n","from torch_scatter import scatter_add\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n","from torch_geometric.nn.inits import glorot, zeros\n","import pdb\n","\n","class GCNConv(MessagePassing):\n","\n","    def __init__(self,\n","                 in_channels,\n","                 out_channels,\n","                 improved=False,\n","                 cached=False,\n","                 bias=True,\n","                 edge_norm=True,\n","                 gfn=False):\n","        super(GCNConv, self).__init__('add')\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.improved = improved\n","        self.cached = cached\n","        self.cached_result = None\n","        self.edge_norm = edge_norm\n","        self.gfn = gfn\n","        self.message_mask = None\n","        self.weight = Parameter(torch.Tensor(in_channels, out_channels))\n","\n","        if bias:\n","            self.bias = Parameter(torch.Tensor(out_channels))\n","        else:\n","            self.register_parameter('bias', None)\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        glorot(self.weight)\n","        zeros(self.bias)\n","        self.cached_result = None\n","\n","    @staticmethod\n","    def norm(edge_index, num_nodes, edge_weight, improved=False, dtype=None):\n","        if edge_weight is None:\n","            edge_weight = torch.ones((edge_index.size(1), ),\n","                                     dtype=dtype,\n","                                     device=edge_index.device)\n","\n","        edge_weight = edge_weight.view(-1)\n","\n","\n","        assert edge_weight.size(0) == edge_index.size(1)\n","\n","        edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)\n","        edge_index, _ = add_self_loops(edge_index, num_nodes=num_nodes)\n","        # Add edge_weight for loop edges.\n","        loop_weight = torch.full((num_nodes, ),\n","                                 1 if not improved else 2,\n","                                 dtype=edge_weight.dtype,\n","                                 device=edge_weight.device)\n","        edge_weight = torch.cat([edge_weight, loop_weight], dim=0)\n","\n","        row, col = edge_index\n","        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n","\n","        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n","\n","    def forward(self, x, edge_index, edge_weight=None):\n","        \"\"\"\"\"\"\n","\n","        x = torch.matmul(x, self.weight)\n","        if self.gfn:\n","            return x\n","\n","        if not self.cached or self.cached_result is None:\n","            if self.edge_norm:\n","                edge_index, norm = GCNConv.norm(\n","                    edge_index,\n","                    x.size(0),\n","                    edge_weight,\n","                    self.improved,\n","                    x.dtype)\n","            else:\n","                norm = None\n","            self.cached_result = edge_index, norm\n","\n","        edge_index, norm = self.cached_result\n","        return self.propagate(edge_index, x=x, norm=norm)\n","\n","    def message(self, x_j, norm):\n","\n","        if self.edge_norm:\n","            return norm.view(-1, 1) * x_j\n","        else:\n","            return x_j\n","\n","    def update(self, aggr_out):\n","        if self.bias is not None:\n","            aggr_out = aggr_out + self.bias\n","        return aggr_out\n","\n","    def __repr__(self):\n","        return '{}({}, {})'.format(self.__class__.__name__, self.in_channels,\n","                                   self.out_channels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jCXZmqIT4gvJ"},"outputs":[],"source":["from functools import partial\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.nn import Linear, BatchNorm1d, Sequential, ReLU\n","from torch_geometric.nn import global_mean_pool, global_add_pool, GINConv, GATConv\n","\n","import random\n","import pdb\n","device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n","\n","layers=3\n","with_random=True\n","fc_num=222\n","hidden=32\n","eval_random=False\n","class causalpreCO(torch.nn.Module):\n","  def __init__(self, num_features,num_classes,gfn=False,collapse=False,residual=False,\n","                      res_branch=\"BNConvReLU\",\n","                      global_pool=\"sum\",\n","                      dropout=0,\n","                      edge_norm=True):\n","    super(causalpreCO, self).__init__()\n","    num_conv_layers = layers\n","    self.global_pool = global_add_pool\n","\n","    self.with_random = with_random\n","    GConv = partial(GCNConv, edge_norm=edge_norm, gfn=gfn)\n","    self.bno= BatchNorm1d(hidden)\n","    self.context_convs = GConv(hidden, hidden)\n","    self.objects_convs = GConv(hidden, hidden)\n","\n","\n","    hidden_in = num_features\n","    self.num_classes = num_classes\n","    hidden_out = num_classes\n","    self.fc_num = fc_num\n","\n","    self.object_mlp=torch.nn.Sequential(\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden),\n","        ReLU(),\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden_out)\n","    )\n","\n","\n","    # BN initialization.\n","    for m in self.modules():\n","        if isinstance(m, (torch.nn.BatchNorm1d)):\n","            torch.nn.init.constant_(m.weight, 1)\n","            torch.nn.init.constant_(m.bias,0.0001)\n","\n","  def forward(self,causal,edge_index,causal_edge_weight,batch,eval_random=True):\n","\n","\n","    xo = F.relu(self.objects_convs(self.bno(causal), edge_index, causal_edge_weight))\n","\n","    #xc_logis = self.context_readout_layer(xc)\n","    #xo_logis = self.objects_readout_layer(xo)\n","    #xco_logis = self.random_readout_layer(xc, xo, eval_random=eval_random)\n","\n","    #return xc_logis, xo_logis, xco_logis\n","    return self.objects_readout_layer(xo,batch)\n","\n","\n","\n","\n","  def objects_readout_layer(self,x,batch):\n","      xo = self.global_pool(x, batch)\n","      x_logis = F.log_softmax(self.object_mlp(xo), dim=-1)\n","      return x_logis\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_8tmkAd_kRR"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epKUsoafv8Wv"},"outputs":[],"source":["class causalpreNO(torch.nn.Module):\n","  def __init__(self, num_features,num_classes,gfn=False,collapse=False,residual=False,\n","                      res_branch=\"BNConvReLU\",\n","                      global_pool=\"sum\",\n","                      dropout=0,\n","                      edge_norm=True):\n","    super(causalpreNO, self).__init__()\n","    num_conv_layers = layers\n","\n","    self.global_pool = global_add_pool\n","\n","    self.with_random = with_random\n","\n","    GConv = partial(GCNConv, edge_norm=edge_norm, gfn=gfn)\n","\n","    hidden_in = num_features\n","    self.num_classes = num_classes\n","    hidden_out = num_classes\n","    self.fc_num = fc_num\n","    self.bnc = BatchNorm1d(hidden)\n","    self.bno= BatchNorm1d(hidden)\n","    self.context_convs = GConv(hidden, hidden)\n","    self.objects_convs = GConv(hidden, hidden)\n","\n","    self.context_mlp=torch.nn.Sequential(\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden),\n","        ReLU(),\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden_out)\n","    )\n","\n","    self.random_readout_mlp=torch.nn.Sequential(\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden),\n","        ReLU(),\n","        BatchNorm1d(hidden),\n","        Linear(hidden, hidden_out)\n","    )\n","    #else:\n","      #   assert False\n","\n","    # BN initialization.\n","    for m in self.modules():\n","        if isinstance(m, (torch.nn.BatchNorm1d)):\n","            torch.nn.init.constant_(m.weight, 1)\n","            torch.nn.init.constant_(m.bias, 0.0001)\n","\n","  #def forward(self,causal,noncausal,batch,causal_edge_weight,noncausal_edge_weight,edge_index,eval_random=True):\n","  def forward(self,causal,noncausal,edge_index,causal_edge_weight,noncausal_edge_weight,batch,eval_random=True):\n","\n","    xc = F.relu(self.context_convs(self.bnc(noncausal), edge_index, noncausal_edge_weight))\n","    xo = F.relu(self.objects_convs(self.bno(causal), edge_index, causal_edge_weight))\n","\n","    xc = self.global_pool(xc, batch)\n","    xo = self.global_pool(xo, batch)\n","\n","    xc_logis = self.context_readout_layer(xc)\n","    #xo_logis = self.objects_readout_layer(xo)\n","    xco_logis = self.random_readout_layer(xc, xo, eval_random=eval_random)\n","\n","    return xc_logis, xco_logis\n","\n","\n","  def context_readout_layer(self, x):\n","\n","\n","      x_logis = F.log_softmax(self.context_mlp(x), dim=-1)\n","      return x_logis\n","\n","  def random_readout_layer(self, xc, xo, eval_random):\n","\n","      num = xc.shape[0]\n","      l = [i for i in range(num)]\n","      if self.with_random:\n","          if eval_random:\n","              random.shuffle(l)\n","      random_idx = torch.tensor(l)\n","      #if self.args.cat_or_add == \"cat\":\n","      #    x = torch.cat((xc[random_idx], xo), dim=1)\n","      #else:\n","      x = xc[random_idx] + xo\n","\n","      x_logis = F.log_softmax(self.random_readout_mlp(x), dim=-1)\n","      return x_logis\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64_EwVWmnugN"},"outputs":[],"source":["class CausalGAN(torch.nn.Module):\n","    \"\"\"GCN with BN and residual connection.\"\"\"\n","    def __init__(self, num_features,\n","                       num_classes,\n","                       gfn=False,\n","                       collapse=False,\n","                       residual=False,\n","                       res_branch=\"BNConvReLU\",\n","                       global_pool=\"sum\",\n","                       dropout=0.2,\n","                       edge_norm=True):\n","        super(CausalGAN, self).__init__()\n","        num_conv_layers = layers\n","        #hidden = args.hidden\n","        #self.args = args\n","        hidden=32\n","        head=4\n","        self.global_pool = global_add_pool\n","        self.dropout = dropout\n","        self.with_random = with_random\n","        self.without_node_attention = False\n","        self.without_edge_attention = False\n","        GConv = partial(GCNConv, edge_norm=edge_norm, gfn=gfn)\n","\n","        hidden_in = num_features\n","        self.num_classes = num_classes\n","        hidden_out = num_classes\n","        self.fc_num = fc_num\n","        self.bn_feat = BatchNorm1d(hidden_in)\n","        self.conv_feat = GCNConv(hidden_in, hidden, gfn=True) # linear transform\n","        self.bns_conv = torch.nn.ModuleList()\n","        self.convs = torch.nn.ModuleList()\n","\n","        for i in range(num_conv_layers):\n","            self.bns_conv.append(BatchNorm1d(hidden))\n","            self.convs.append(GATConv(hidden, int(hidden / head), heads=head, dropout=dropout))\n","\n","        self.edge_att_mlp = nn.Linear(hidden * 2, 2)\n","        self.node_att_mlp = nn.Linear(hidden, 2)\n","        self.bnc = BatchNorm1d(hidden)\n","        self.bno= BatchNorm1d(hidden)\n","        self.context_convs = GConv(hidden, hidden)\n","        self.objects_convs = GConv(hidden, hidden)\n","        self.relu = nn.ReLU(inplace=False)\n","\n","        for m in self.modules():\n","            if isinstance(m, (torch.nn.BatchNorm1d)):\n","                torch.nn.init.constant_(m.weight, 1)\n","                torch.nn.init.constant_(m.bias, 0.0001)\n","\n","    def forward(self, data, eval_random=True):\n","\n","        x = data.x if data.x is not None else data.feat# x is the graph feature\n","        edge_index,edge_attr,batch = data.edge_index,data.edge_attr,data.batch\n","        row, col = edge_index\n","        x = self.bn_feat(x)\n","        x = self.relu(self.conv_feat(x, edge_index,edge_weight=edge_attr))\n","\n","        for i, conv in enumerate(self.convs):\n","            x = self.bns_conv[i](x)\n","            x = self.relu(conv(x, edge_index))\n","\n","        edge_rep = torch.cat([x[row], x[col]], dim=-1)\n","\n","        if self.without_edge_attention:\n","            edge_att = 0.5 * torch.ones(edge_rep.shape[0], 2).to(device)\n","        else:\n","            edge_att = F.softmax(self.edge_att_mlp(edge_rep), dim=-1)\n","        edge_weight_c = edge_att[:, 0]\n","        edge_weight_o = edge_att[:, 1]\n","\n","        if self.without_node_attention:\n","            node_att = 0.5 * torch.ones(x.shape[0], 2).to(device)\n","        else:\n","            node_att = F.softmax(self.node_att_mlp(x), dim=-1)\n","        xc = node_att[:, 0].view(-1, 1) * x\n","        xo = node_att[:, 1].view(-1, 1) * x\n","\n","        #print(edge_weight_o)\n","        #xc = F.relu(self.context_convs(self.bnc(xc), edge_index, edge_weight_c))\n","        #xo = F.relu(self.objects_convs(self.bno(xo), edge_index, edge_weight_o))\n","        #node_of_graph=xo.shape[0]\n","        #causal_part,causal_node=split_graph(graph_x=xo,node_of_graph=node_of_graph)\n","        #noncausal_part,noncausal_node=split_graph(graph_x=xc,node_of_graph=node_of_graph,type_of_graph=False)\n","\n","        #xc = self.global_pool(xc, batch)\n","        #xo = self.global_pool(xo, batch)\n","\n","        #xc_logis = self.context_readout_layer(xc)\n","        #xo_logis = self.objects_readout_layer(xo)\n","        #xco_logis = self.random_readout_layer(xc, xo, eval_random=eval_random)\n","\n","      # return (xo,edge_index,edge_weight_o),(xc,edge_index,edge_weight_c),batch\n","        return (xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch\n","        #return (causal_attention,causal_part,causal_node),(noncausal_attention,noncausal_part,noncausal_node),batch\n","        #return (xo,causal_part,causal_node),(xc,noncausal_part,noncausal_node),batch\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85yBn66PB_QG"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch_geometric.datasets import Planetoid\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.data import DataLoader\n","\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import CosineAnnealingLR\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ewtiaFv7H4AC"},"outputs":[],"source":["train_loader = DataLoader(training_final, batch_size=128, shuffle=True)\n","val_loader = DataLoader(valing_final, batch_size=128, shuffle=False)\n","test_loader = DataLoader(testing_final, batch_size=128, shuffle=False)\n","#t_load=[]\n","#for i in train_loader:\n","#  t_load.append(i)\n","#  if(len(t_load)==10000):\n","#    break\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqj2r-DqOxaT"},"outputs":[],"source":["number_of_class=10\n","\n","causal_model2 = CausalGAN(7,number_of_class).to(device)\n","predictno_model2=causalpreNO(7,number_of_class).to(device)\n","predictco_model2=causalpreCO(7,number_of_class).to(device)\n","model_optimizer2 = torch.optim.Adam(\n","            list(causal_model2.parameters()) +\n","            list(predictno_model2.parameters())+list(predictco_model2.parameters()),\n","            lr=0.001)\n","Epo=500\n","lr_scheduler = CosineAnnealingLR(model_optimizer2, T_max=Epo, eta_min=1e-6, last_epoch=-1, verbose=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1687075627189,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"SGHHtOmt2Ct_","outputId":"7389a101-9747-49ad-94bc-1152f9c2ae70"},"outputs":[{"data":{"text/plain":["causalpreNO(\n","  (bnc): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bno): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (context_convs): GCNConv(32, 32)\n","  (objects_convs): GCNConv(32, 32)\n","  (context_mlp): Sequential(\n","    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (1): Linear(in_features=32, out_features=32, bias=True)\n","    (2): ReLU()\n","    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=32, out_features=10, bias=True)\n","  )\n","  (random_readout_mlp): Sequential(\n","    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (1): Linear(in_features=32, out_features=32, bias=True)\n","    (2): ReLU()\n","    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=32, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["predictno_model2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1687075627190,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"cmbAh_ZSipBd","outputId":"f627d1c2-ba02-4981-929f-7a091c056603"},"outputs":[{"data":{"text/plain":["CausalGAN(\n","  (bn_feat): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv_feat): GCNConv(7, 32)\n","  (bns_conv): ModuleList(\n","    (0-2): 3 x BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (convs): ModuleList(\n","    (0-2): 3 x GATConv(32, 8, heads=4)\n","  )\n","  (edge_att_mlp): Linear(in_features=64, out_features=2, bias=True)\n","  (node_att_mlp): Linear(in_features=32, out_features=2, bias=True)\n","  (bnc): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bno): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (context_convs): GCNConv(32, 32)\n","  (objects_convs): GCNConv(32, 32)\n","  (relu): ReLU()\n",")"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["causal_model2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1687075627190,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"nkxDWAoriqov","outputId":"745f1fd7-fc73-4e7e-a410-1770cc61e5e3"},"outputs":[{"data":{"text/plain":["causalpreCO(\n","  (bnc): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (bno): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (context_convs): GCNConv(32, 32)\n","  (objects_convs): GCNConv(32, 32)\n","  (object_mlp): Sequential(\n","    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (1): Linear(in_features=32, out_features=32, bias=True)\n","    (2): ReLU()\n","    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): Linear(in_features=32, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["predictco_model2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1758301,"status":"ok","timestamp":1687083421802,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"NvidGrhFBdK4","outputId":"d7d54dda-d16e-4a3b-e165-2a2a37d89a66"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----training-------0\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [0/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.0705]\n"]},{"name":"stdout","output_type":"stream","text":["number of 0 with total loss:0.3048795245682137\n","------valation---------0\n","causal val accuracy:0.1317\n","-----training-------1\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [1/500]: 100%|██████████| 79/79 [00:26<00:00,  3.02it/s, loss=1.19]\n"]},{"name":"stdout","output_type":"stream","text":["number of 1 with total loss:0.314138225550893\n","------valation---------1\n","causal val accuracy:0.1325\n","-----training-------2\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [2/500]: 100%|██████████| 79/79 [00:26<00:00,  3.02it/s, loss=0.0527]\n"]},{"name":"stdout","output_type":"stream","text":["number of 2 with total loss:0.3040312711102299\n","------valation---------2\n","causal val accuracy:0.1293\n","-----training-------3\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [3/500]: 100%|██████████| 79/79 [00:25<00:00,  3.06it/s, loss=2.08]\n"]},{"name":"stdout","output_type":"stream","text":["number of 3 with total loss:0.3154669989702068\n","------valation---------3\n","causal val accuracy:0.1323\n","-----training-------4\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [4/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=0.0539]\n"]},{"name":"stdout","output_type":"stream","text":["number of 4 with total loss:0.3031241858873186\n","------valation---------4\n","causal val accuracy:0.1229\n","-----training-------5\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [5/500]: 100%|██████████| 79/79 [00:25<00:00,  3.05it/s, loss=0.07]\n"]},{"name":"stdout","output_type":"stream","text":["number of 5 with total loss:0.275000852403007\n","------valation---------5\n","causal val accuracy:0.1296\n","-----training-------6\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [6/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=0.323]\n"]},{"name":"stdout","output_type":"stream","text":["number of 6 with total loss:0.27466497211893903\n","------valation---------6\n","causal val accuracy:0.145\n","-----training-------7\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [7/500]: 100%|██████████| 79/79 [00:26<00:00,  3.03it/s, loss=0.276]\n"]},{"name":"stdout","output_type":"stream","text":["number of 7 with total loss:0.27186820231661013\n","------valation---------7\n","causal val accuracy:0.1462\n","-----training-------8\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [8/500]: 100%|██████████| 79/79 [00:26<00:00,  2.98it/s, loss=1.05]\n"]},{"name":"stdout","output_type":"stream","text":["number of 8 with total loss:0.2738705337802066\n","------valation---------8\n","causal val accuracy:0.1539\n","-----training-------9\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [9/500]: 100%|██████████| 79/79 [00:26<00:00,  3.00it/s, loss=0.364]\n"]},{"name":"stdout","output_type":"stream","text":["number of 9 with total loss:0.26363529378100287\n","------valation---------9\n","causal val accuracy:0.1606\n","-----training-------10\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [10/500]: 100%|██████████| 79/79 [00:26<00:00,  2.98it/s, loss=0.453]\n"]},{"name":"stdout","output_type":"stream","text":["number of 10 with total loss:0.2620445373880712\n","------valation---------10\n","causal val accuracy:0.1612\n","-----training-------11\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [11/500]: 100%|██████████| 79/79 [00:26<00:00,  2.95it/s, loss=0.0369]\n"]},{"name":"stdout","output_type":"stream","text":["number of 11 with total loss:0.24904592410673068\n","------valation---------11\n","causal val accuracy:0.1743\n","-----training-------12\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [12/500]: 100%|██████████| 79/79 [00:26<00:00,  3.00it/s, loss=0.331]\n"]},{"name":"stdout","output_type":"stream","text":["number of 12 with total loss:0.25526379661846765\n","------valation---------12\n","causal val accuracy:0.1744\n","-----training-------13\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [13/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.272]\n"]},{"name":"stdout","output_type":"stream","text":["number of 13 with total loss:0.2419078054873249\n","------valation---------13\n","causal val accuracy:0.1765\n","-----training-------14\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [14/500]: 100%|██████████| 79/79 [00:26<00:00,  2.93it/s, loss=1]\n"]},{"name":"stdout","output_type":"stream","text":["number of 14 with total loss:0.2513344680206685\n","------valation---------14\n","causal val accuracy:0.1764\n","-----training-------15\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [15/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.363]\n"]},{"name":"stdout","output_type":"stream","text":["number of 15 with total loss:0.23613086276793782\n","------valation---------15\n","causal val accuracy:0.184\n","-----training-------16\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [16/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.499]\n"]},{"name":"stdout","output_type":"stream","text":["number of 16 with total loss:0.236538612201244\n","------valation---------16\n","causal val accuracy:0.1708\n","-----training-------17\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [17/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=0.573]\n"]},{"name":"stdout","output_type":"stream","text":["number of 17 with total loss:0.24523108707198613\n","------valation---------17\n","causal val accuracy:0.1723\n","-----training-------18\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [18/500]: 100%|██████████| 79/79 [00:26<00:00,  2.95it/s, loss=0.306]\n"]},{"name":"stdout","output_type":"stream","text":["number of 18 with total loss:0.22837826670913758\n","------valation---------18\n","causal val accuracy:0.1687\n","-----training-------19\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [19/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.377]\n"]},{"name":"stdout","output_type":"stream","text":["number of 19 with total loss:0.22639869978722138\n","------valation---------19\n","causal val accuracy:0.1677\n","-----training-------20\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [20/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.16]\n"]},{"name":"stdout","output_type":"stream","text":["number of 20 with total loss:0.22185713015025174\n","------valation---------20\n","causal val accuracy:0.1722\n","-----training-------21\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [21/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.304]\n"]},{"name":"stdout","output_type":"stream","text":["number of 21 with total loss:0.2232338967202585\n","------valation---------21\n","causal val accuracy:0.1906\n","-----training-------22\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [22/500]: 100%|██████████| 79/79 [00:27<00:00,  2.87it/s, loss=0.393]\n"]},{"name":"stdout","output_type":"stream","text":["number of 22 with total loss:0.21573838407668885\n","------valation---------22\n","causal val accuracy:0.1922\n","-----training-------23\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [23/500]: 100%|██████████| 79/79 [00:27<00:00,  2.91it/s, loss=0.124]\n"]},{"name":"stdout","output_type":"stream","text":["number of 23 with total loss:0.21384379201674764\n","------valation---------23\n","causal val accuracy:0.1785\n","-----training-------24\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [24/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.548]\n"]},{"name":"stdout","output_type":"stream","text":["number of 24 with total loss:0.2164500148235997\n","------valation---------24\n","causal val accuracy:0.1988\n","-----training-------25\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [25/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.963]\n"]},{"name":"stdout","output_type":"stream","text":["number of 25 with total loss:0.24300711045536813\n","------valation---------25\n","causal val accuracy:0.1935\n","-----training-------26\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [26/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=0.649]\n"]},{"name":"stdout","output_type":"stream","text":["number of 26 with total loss:0.2245760115830204\n","------valation---------26\n","causal val accuracy:0.1944\n","-----training-------27\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [27/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.326]\n"]},{"name":"stdout","output_type":"stream","text":["number of 27 with total loss:0.231768184258968\n","------valation---------27\n","causal val accuracy:0.1827\n","-----training-------28\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [28/500]: 100%|██████████| 79/79 [00:26<00:00,  2.98it/s, loss=0.55]\n"]},{"name":"stdout","output_type":"stream","text":["number of 28 with total loss:0.2077289605631104\n","------valation---------28\n","causal val accuracy:0.1978\n","-----training-------29\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [29/500]: 100%|██████████| 79/79 [00:26<00:00,  3.00it/s, loss=0.592]\n"]},{"name":"stdout","output_type":"stream","text":["number of 29 with total loss:0.19859673078112963\n","------valation---------29\n","causal val accuracy:0.2008\n","-----training-------30\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [30/500]: 100%|██████████| 79/79 [00:26<00:00,  3.00it/s, loss=0.223]\n"]},{"name":"stdout","output_type":"stream","text":["number of 30 with total loss:0.19586315241795552\n","------valation---------30\n","causal val accuracy:0.2071\n","-----training-------31\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [31/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.0381]\n"]},{"name":"stdout","output_type":"stream","text":["number of 31 with total loss:0.18980811022316355\n","------valation---------31\n","causal val accuracy:0.2155\n","-----training-------32\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [32/500]: 100%|██████████| 79/79 [00:26<00:00,  3.01it/s, loss=0.308]\n"]},{"name":"stdout","output_type":"stream","text":["number of 32 with total loss:0.18150066843704332\n","------valation---------32\n","causal val accuracy:0.1992\n","-----training-------33\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [33/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=0.111]\n"]},{"name":"stdout","output_type":"stream","text":["number of 33 with total loss:0.1833477769565733\n","------valation---------33\n","causal val accuracy:0.2128\n","-----training-------34\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [34/500]: 100%|██████████| 79/79 [00:26<00:00,  2.98it/s, loss=0.0987]\n"]},{"name":"stdout","output_type":"stream","text":["number of 34 with total loss:0.1793219107615797\n","------valation---------34\n","causal val accuracy:0.2331\n","-----training-------35\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [35/500]: 100%|██████████| 79/79 [00:26<00:00,  2.95it/s, loss=0.394]\n"]},{"name":"stdout","output_type":"stream","text":["number of 35 with total loss:0.18221989344758324\n","------valation---------35\n","causal val accuracy:0.2142\n","-----training-------36\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [36/500]: 100%|██████████| 79/79 [00:26<00:00,  2.95it/s, loss=0.0618]\n"]},{"name":"stdout","output_type":"stream","text":["number of 36 with total loss:0.1790798903454708\n","------valation---------36\n","causal val accuracy:0.2081\n","-----training-------37\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [37/500]: 100%|██████████| 79/79 [00:26<00:00,  2.99it/s, loss=1.04]\n"]},{"name":"stdout","output_type":"stream","text":["number of 37 with total loss:0.18776150679663767\n","------valation---------37\n","causal val accuracy:0.2305\n","-----training-------38\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [38/500]: 100%|██████████| 79/79 [00:26<00:00,  2.93it/s, loss=0.451]\n"]},{"name":"stdout","output_type":"stream","text":["number of 38 with total loss:0.1873721974559977\n","------valation---------38\n","causal val accuracy:0.2281\n","-----training-------39\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [39/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.164]\n"]},{"name":"stdout","output_type":"stream","text":["number of 39 with total loss:0.16908480500495887\n","------valation---------39\n","causal val accuracy:0.2377\n","-----training-------40\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [40/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.267]\n"]},{"name":"stdout","output_type":"stream","text":["number of 40 with total loss:0.17355877118585986\n","------valation---------40\n","causal val accuracy:0.2158\n","-----training-------41\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [41/500]: 100%|██████████| 79/79 [00:26<00:00,  2.96it/s, loss=0.119]\n"]},{"name":"stdout","output_type":"stream","text":["number of 41 with total loss:0.17591163379293454\n","------valation---------41\n","causal val accuracy:0.2377\n","-----training-------42\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [42/500]: 100%|██████████| 79/79 [00:26<00:00,  2.97it/s, loss=0.145]\n"]},{"name":"stdout","output_type":"stream","text":["number of 42 with total loss:0.16577068197576306\n","------valation---------42\n","causal val accuracy:0.23\n","-----training-------43\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [43/500]: 100%|██████████| 79/79 [00:26<00:00,  2.93it/s, loss=0.801]\n"]},{"name":"stdout","output_type":"stream","text":["number of 43 with total loss:0.17872118299143225\n","------valation---------43\n","causal val accuracy:0.2427\n","-----training-------44\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [44/500]: 100%|██████████| 79/79 [00:26<00:00,  2.93it/s, loss=0.0804]\n"]},{"name":"stdout","output_type":"stream","text":["number of 44 with total loss:0.16865794827477842\n","------valation---------44\n","causal val accuracy:0.2492\n","-----training-------45\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [45/500]: 100%|██████████| 79/79 [00:26<00:00,  2.94it/s, loss=0.246]\n"]},{"name":"stdout","output_type":"stream","text":["number of 45 with total loss:0.15868688162557687\n","------valation---------45\n","causal val accuracy:0.252\n","-----training-------46\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [46/500]: 100%|██████████| 79/79 [00:26<00:00,  2.94it/s, loss=0.966]\n"]},{"name":"stdout","output_type":"stream","text":["number of 46 with total loss:0.17299702197690553\n","------valation---------46\n","causal val accuracy:0.2772\n","-----training-------47\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [47/500]: 100%|██████████| 79/79 [00:27<00:00,  2.91it/s, loss=1.21]\n"]},{"name":"stdout","output_type":"stream","text":["number of 47 with total loss:0.1849257016106497\n","------valation---------47\n","causal val accuracy:0.2435\n","-----training-------48\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [48/500]: 100%|██████████| 79/79 [00:27<00:00,  2.88it/s, loss=0.289]\n"]},{"name":"stdout","output_type":"stream","text":["number of 48 with total loss:0.17160043648526638\n","------valation---------48\n","causal val accuracy:0.2438\n","-----training-------49\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [49/500]: 100%|██████████| 79/79 [00:27<00:00,  2.88it/s, loss=0.0681]\n"]},{"name":"stdout","output_type":"stream","text":["number of 49 with total loss:0.1514893762201448\n","------valation---------49\n","causal val accuracy:0.2608\n","-----training-------50\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [50/500]: 100%|██████████| 79/79 [00:27<00:00,  2.92it/s, loss=0.0312]\n"]},{"name":"stdout","output_type":"stream","text":["number of 50 with total loss:0.14615903629720967\n","------valation---------50\n","causal val accuracy:0.2475\n","-----training-------51\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [51/500]: 100%|██████████| 79/79 [00:26<00:00,  3.01it/s, loss=0.945]\n"]},{"name":"stdout","output_type":"stream","text":["number of 51 with total loss:0.1544845375833632\n","------valation---------51\n","causal val accuracy:0.2477\n"]}],"source":["import time\n","import json\n","\n","loss_value=[]\n","loss_value_valation=[]\n","c=0.5\n","o=1\n","co=0.5\n","def num_graphs(data):\n","  if data.batch is not None:\n","      return data.num_graphs\n","  else:\n","      return data.x.size(0)\n","from tqdm import tqdm\n","\n","for epoch in range(Epo):\n","  #model.train()\n","  causal_model2.train()\n","  predictno_model2.train()\n","  predictco_model2.train()\n","  total_loss = 0\n","  total_loss_c = 0\n","  total_loss_o = 0\n","  total_loss_co = 0\n","  correct_o = 0\n","  nb=0\n","  print(f\"-----training-------{epoch}\")\n","  loop = tqdm(enumerate(train_loader),total=len(train_loader))\n","  for it, data in loop:\n","#  for it, data in enumerate(train_loader):\n","      nb+=1\n","      model_optimizer2.zero_grad()\n","      data = data.to(device)\n","\n","      one_hot_target = data.y.view(-1)\n","      #causal,noncausal,batch=causal_model(data)\n","      (xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(data)\n","      #c_logs, o_logs, co_logs = predict_model(causal=causal,noncausal=noncausal,batch=batch,causal_edge_weight=edge_weight_causal,noncausal_edge_weight=edge_weight_noncausal,edge_index=edge_index)\n","      c_logs,co_logs = predictno_model2(causal=xo,noncausal=xc,edge_index=edge_index,causal_edge_weight=edge_weight_o,noncausal_edge_weight=edge_weight_c,batch=batch)\n","      o_logs=predictco_model2(causal=xo,edge_index=edge_index,causal_edge_weight=edge_weight_o,batch=batch)\n","      uniform_target = torch.ones_like(c_logs, dtype=torch.float).to(device)/number_of_class\n","     # sim=F.cosine_similarity(causal_attention,noncausal_attention).mean()\n","      #print(o_logs)\n","      #print(type(o_logs))\n","      c_loss = F.kl_div(c_logs, uniform_target,reduction='batchmean')\n","      #print(f'causal loss{c_loss}')\n","      o_loss = F.nll_loss(o_logs,one_hot_target)\n","      #print(f'noncausal loss{o_loss}')\n","      co_loss = F.nll_loss(co_logs,one_hot_target)\n","      #print(f'com causal loss{co_loss}')\n","      loss = c * c_loss + o * o_loss + co * co_loss\n","\n","      pred_o = o_logs.max(1)[1]\n","      correct_o += pred_o.eq(data.y.view(-1)).sum().item()\n","      loss.backward()\n","      total_loss += loss.item() #* num_graphs(data)\n","      total_loss_c += c_loss.item() #* num_graphs(data)\n","      total_loss_o += o_loss.item() #* num_graphs(data)\n","      total_loss_co += co_loss.item()# * num_graphs(data)\n","      model_optimizer2.step()\n","      loop.set_description(f\"Epoch [{epoch}/{Epo}]\")\n","      loop.set_postfix(loss = loss.item())\n","\n","  #num = len(train_loader.dataset)\n","  lr_scheduler.step()\n","  total_loss = total_loss / nb\n","  total_loss_c = total_loss_c / nb\n","  print(f'number of {epoch} with total loss:{total_loss}')\n","  loss_value.append(total_loss)\n","  total_loss_o = total_loss_o / nb\n","  total_loss_co = total_loss_co / nb\n","  correct_o = correct_o / nb\n","  with torch.no_grad():\n","    correct=0\n","    correct_c=0\n","    correct_o=0\n","    print(f\"------valation---------{epoch}\")\n","    causal_model2.eval()\n","    predictno_model2.eval()\n","    predictco_model2.eval()\n","    for data in val_loader:\n","      (xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(data)\n","      #c_logs, o_logs, co_logs = predict_model(causal=causal,noncausal=noncausal,batch=batch,causal_edge_weight=edge_weight_causal,noncausal_edge_weight=edge_weight_noncausal,edge_index=edge_index)\n","      c_logs,co_logs = predictno_model2(causal=xo,noncausal=xc,edge_index=edge_index,causal_edge_weight=edge_weight_o,noncausal_edge_weight=edge_weight_c,batch=batch)\n","      o_logs=predictco_model2(causal=xo,edge_index=edge_index,causal_edge_weight=edge_weight_o,batch=batch)\n","      pred = co_logs.max(1)[1]\n","      pred_c = c_logs.max(1)[1]\n","      pred_o = o_logs.max(1)[1]\n","      correct += pred.eq(data.y.view(-1)).sum().item()\n","      correct_c += pred_c.eq(data.y.view(-1)).sum().item()\n","      correct_o += pred_o.eq(data.y.view(-1)).sum().item()\n","    acc_co = correct / len(val_loader.dataset)\n","    acc_c = correct_c / len(val_loader.dataset)\n","    acc_o = correct_o / len(val_loader.dataset)\n","    print(f\"causal val accuracy:{acc_co}\")\n","    loss_value_valation.append(acc_co)\n","    dictionary={\"number of epoch\":epoch,\n","                \"training loss list\":loss_value,\n","                \"valation accuracy list\":loss_value_valation}\n","\n","    # Serializing json\n","    json_object = json.dumps(dictionary,indent=3)\n","\n","    # Writing to sample.json\n","   # with open(\"/content/drive/MyDrive/running_cal_mnist/number_tl_va_e08.json\", \"w\") as outfile:\n","   #     outfile.write(json_object)\n","\n","    torch.save({\n","            'causal_model.state_dic': causal_model2.state_dict(),\n","            'predictco_model_state_dict()': predictco_model2.state_dict(),\n","            'predictno_model_state_dict()': predictno_model2.state_dict(),\n","            'opt':model_optimizer2.state_dict()\n","            }, '/content/drive/MyDrive/running_cal_mnist/allmodel_cal_9533.pt')\n","    if(epoch>50):\n","      check=abs(acc_o-loss_value_valation[len(loss_value_valation)-20])/20\n","      if(check<=0.01):\n","        break\n","\n","\n","  #model_optimizer.zero_grad()\n","  #total_loss.backward()\n","  #model_optimizer.step()\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"executionInfo":{"elapsed":74,"status":"error","timestamp":1686899240881,"user":{"displayName":"LI-CHENG YEH","userId":"17628358221149984922"},"user_tz":-720},"id":"TtHc-ubJ4uAW","outputId":"46a13968-275e-4d3b-a6aa-c4a94019d920"},"outputs":[{"ename":"SyntaxError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-c6358e1aa0e1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sa a a\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["sa a a"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wDmrzjd3ofrc"},"outputs":[],"source":["correct=0\n","correct_c=0\n","correct_o=0\n","print(f\"------test---------{0000000}\")\n","causal_model2.eval()\n","predictno_model2.eval()\n","predictco_model2.eval()\n","for data in test_loader:\n","  (xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(data)\n","  #c_logs, o_logs, co_logs = predict_model(causal=causal,noncausal=noncausal,batch=batch,causal_edge_weight=edge_weight_causal,noncausal_edge_weight=edge_weight_noncausal,edge_index=edge_index)\n","  c_logs,co_logs = predictno_model2(causal=xo,noncausal=xc,edge_index=edge_index,causal_edge_weight=edge_weight_o,noncausal_edge_weight=edge_weight_c,batch=batch)\n","  o_logs=predictco_model2(causal=xo,edge_index=edge_index,causal_edge_weight=edge_weight_o,batch=batch)\n","  pred = co_logs.max(1)[1]\n","  pred_c = c_logs.max(1)[1]\n","  pred_o = o_logs.max(1)[1]\n","  correct += pred.eq(data.y.view(-1)).sum().item()\n","  correct_c += pred_c.eq(data.y.view(-1)).sum().item()\n","  correct_o += pred_o.eq(data.y.view(-1)).sum().item()\n","acc_co = correct / len(test_loader.dataset)\n","acc_c = correct_c / len(test_loader.dataset)\n","acc_o = correct_o / len(test_loader.dataset)\n","print(f\"causal test accuracy:{acc_o}\")\n","dictionary={\"number of epoch\":epoch,\n","            \"training loss list\":loss_value,\n","            \"valation accuracy list\":loss_value_valation,\n","            \"test accuracy value\":acc_co}\n","\n","# Serializing json\n","json_object = json.dumps(dictionary,indent=4)\n","\n","# Writing to sample.json\n","with open(\"/content/drive/MyDrive/running_cal_mnist/number_tl_va_e08.json\", \"w\") as outfile:\n","    outfile.write(json_object)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cmcTAfzw9FNF"},"outputs":[],"source":["acc_co"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEUdq94frYUy"},"outputs":[],"source":["checkpoint = torch.load('/content/drive/MyDrive/running_cal_mnist/allmodel_cal_08.pt')\n","causal_model2.load_state_dict(checkpoint['causal_model.state_dic'])\n","predictco_model2.load_state_dict(checkpoint['predictco_model_state_dict()'])\n","predictno_model2.load_state_dict(checkpoint['predictno_model_state_dict()'])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tSV_5LT74ACj"},"outputs":[],"source":["test_loader = DataLoader(testing_final, batch_size=1, shuffle=False)\n","\n","correct=0\n","correct_c=0\n","correct_o=0\n","print(f\"------test---------{0000000}\")\n","causal_model2.eval()\n","predictno_model2.eval()\n","predictco_model2.eval()\n","for data in test_loader:\n","  (xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(data)\n","  #c_logs, o_logs, co_logs = predict_model(causal=causal,noncausal=noncausal,batch=batch,causal_edge_weight=edge_weight_causal,noncausal_edge_weight=edge_weight_noncausal,edge_index=edge_index)\n","  c_logs,co_logs = predictno_model2(causal=xo,noncausal=xc,edge_index=edge_index,causal_edge_weight=edge_weight_o,noncausal_edge_weight=edge_weight_c,batch=batch)\n","  o_logs=predictco_model2(causal=xo,edge_index=edge_index,causal_edge_weight=edge_weight_o,batch=batch)\n","  pred = co_logs.max(1)[1]\n","  pred_c = c_logs.max(1)[1]\n","  pred_o = o_logs.max(1)[1]\n","  correct += pred.eq(data.y.view(-1)).sum().item()\n","  correct_c += pred_c.eq(data.y.view(-1)).sum().item()\n","  correct_o += pred_o.eq(data.y.view(-1)).sum().item()\n","acc_co = correct / len(test_loader.dataset)\n","acc_c = correct_c / len(test_loader.dataset)\n","acc_o = correct_o / len(test_loader.dataset)\n","print(f\"causal test accuracy:{acc_o}\")\n","#dictionary={\"number of epoch\":epoch,\n","#            \"training loss list\":loss_value,\n","#            \"valation accuracy list\":loss_value_valation,\n","#            \"test accuracy value\":acc_co}\n","\n","# Serializing json\n","#json_object = json.dumps(dictionary,indent=4)\n","\n","# Writing to sample.json\n","#with open(\"/content/drive/MyDrive/running_cal_mnist/number_tl_va_e08.json\", \"w\") as outfile:\n"," #   outfile.write(json_object)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ev-dT8Izshh7"},"outputs":[],"source":["aaa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-u7QF44x6he"},"outputs":[],"source":["causal_model2 = CausalGCN(7,number_of_class).to(device)\n","predictco_model2=causalpreCO(7,number_of_class).to(device)\n","\n","causal_model2.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/cau6000.pt'),strict=False)\n","causal_model2.eval()\n","\n","predictco_model2.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/caupred6000.pt'),strict=False)\n","predictco_model2.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykzKIm8eNEaQ"},"outputs":[],"source":["for i in range(len(loss_value)):\n","  loss_value[i]=float(loss_value[i])\n","plt.plot(np.array(loss_value))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wd8sGXpoQK6"},"outputs":[],"source":["\n","import json\n","\n","for epoch in range(10):\n","  if epoch==3:\n","    break\n","\n","\n","# Data to be written\n","dictionary={\"number of epoch\":epoch}\n","# Serializing json\n","json_object = json.dumps(dictionary, indent=1)\n","# Writing to sample.json\n","with open(\"/content/drive/MyDrive/Colab_Notebooks/number_epoch.json\", \"w\") as outfile:\n","    outfile.write(json_object)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yjPmchj9mtoK"},"outputs":[],"source":["for i in parameters_to_prune:\n","  prune.remove(i[0], 'weight')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pd0GCaQ13WA1"},"outputs":[],"source":["for n, w in predictco_model.named_parameters():\n","  fix_para = {n: w < eps for n, w in predictco_model.named_parameters() if n.endswith('weight')}\n","  #print(f\"weight:{sum(w)}\")\n","\n","  if n.endswith('weight'):\n","    print(w)\n","    print(n)\n","\n","\n","\n","\n","print(fix_para)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QnCPHWUNrnJ"},"outputs":[],"source":["plt.plot(np.array(loss_value))\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g4Y3OYHLdOTu"},"outputs":[],"source":["torch.zeros(32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9D2jxZRXENMD"},"outputs":[],"source":["t1=DataLoader(training_final, batch_size=1, shuffle=False)\n","t_load=[]\n","n=0\n","for i in t1:\n","  n+=1\n","  t_load.append(i)\n","n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W1YRp8c06odf"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOYzjqMAu96o"},"outputs":[],"source":["def mask_graph(graph_x,select_node):\n","  mask_value=np.array([0]*32)\n","  result=np.array([t.detach().numpy() for t in graph_x])\n","  for i in range(graph_x.shape[0]):\n","    if(i in select_node):\n","      continue\n","    result[i]=mask_value\n","  return torch.tensor(result)\n","\n","def split_graph(graph_x,node_of_graph,type_of_graph=True):\n","  if(type_of_graph==True):\n","    select_node_number=int(node_of_graph/3)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    #print(select_node)\n","    return mask_graph(graph_x,select_node),select_node\n","  else:\n","    select_node_number=int(node_of_graph/3*2)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    return mask_graph(graph_x,select_node),select_node\n","\n","\n","\n","def conf_u_node(dic,l):\n","  for i in l:\n","    if(i in dic.keys()):\n","      dic[i]+=1\n","      continue\n","    dic[i]=1\n","  return dic\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SLxRjM47b9sq"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRR9ZSPXTJdk"},"outputs":[],"source":["def mask_heter(heter_index,edweig,input_index,input_weight):\n","  edge_list2 = []\n","  for i in range(len(heter_index[0])):\n","    edge_list2.append((int(heter_index[0][i]),int(heter_index[1][i])))\n","\n","  l1=[]\n","  l2=[]\n","  lw=[]\n","  for i in range(len(input_index[0])):\n","    if((int(input_index[0][i]),int(input_index[1][i])) in edge_list2):\n","      continue\n","    l1.append(input_index[0][i])\n","    l2.append(input_index[1][i])\n","    lw.append(input_weight[i])\n","  masked_index=torch.stack([torch.tensor(l1,dtype=torch.long),torch.tensor(l2,dtype=torch.long)]).to(device)\n","  masked_weight=torch.tensor(lw).to(device)\n","  return masked_index,masked_weight"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-CzKmdZPdgfC"},"outputs":[],"source":["def myfunc(a, b):\n","  return a + b\n","\n","x =map(myfunc, ('apple', 'banana', 'cherry'), ('orange', 'lemon', 'pineapple'))\n","list(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYUecDoFdRVr"},"outputs":[],"source":["homo_index[0]\n","homo_index[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXL2jJntih00"},"outputs":[],"source":["x = {\"apple\", \"banana\", \"cherry\"}\n","y = {\"google\", \"microsoft\", \"apple\",\"ww\"}\n","\n","\n","\n","print(y-x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCJN0Zl0j76G"},"outputs":[],"source":["index=torch.LongTensor([[],[]])\n","index1=torch.cat([index1,torch.tensor([[1],[0]])],dim=1)\n","torch.cat([index1,torch.tensor([[1],[0]])],dim=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oq3TOVrc6kZ7"},"outputs":[],"source":["def dd(ed1,ed2,w):\n","  return (int(ed1),int(ed2),float(w))\n","def ff(l):\n","  index=torch.LongTensor([[],[]]).to(device)\n","  weight=torch.tensor([]).to(device)\n","  for i in l:\n","    index=torch.cat([index,torch.tensor([[i[0]],[i[1]]])],dim=1)\n","    weight=torch.cat([weight,torch.tensor([i[2]])])\n","  return index,weight\n","def mask_heter2(heter_index,edweig,input_index,input_weight):\n","  x=map(dd,heter_index[0],heter_index[1],edweig)\n","  x=set(x)\n","  #print(x)\n","  c=map(dd,input_index[0],input_index[1],input_weight)\n","  #list(c)\n","  c=set(c)\n","  f=list(c-x)\n","  return ff(f)\n","start = time.time()\n","\n","mask_heter(homo_index,edweig_coa,edge_index,edge_weight_o)\n","end = time.time()\n","print(end - start)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PXdUhea7ekMD"},"outputs":[],"source":["mask_heter2(homo_index,edweig_coa,edge_index,edge_weight_o)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bt1-RXYnZi6p"},"outputs":[],"source":["(xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(tey)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJF6WTclZoGE"},"outputs":[],"source":["class learning_hetero(torch.nn.Module):\n","   def __init__(self,number_of_class=1):\n","     super(learning_hetero, self).__init__()\n","     self.mlp1 = nn.Linear(hidden*2, number_of_class)\n","     #self.lkrelu = nn.LeakyReLU()\n","     #self.mlp2 = nn.Linear(hidden, number_of_class)\n","     self.sigmod = nn.Sigmoid()\n","\n","   def forward(self,graph,edge_index,batch):\n","     #edge_ho=self.get_label(data,batch)\n","     row, col = edge_index\n","     data=torch.cat([graph[row], graph[col]], dim=-1)\n","     x=self.mlp1(data)\n","     x=self.sigmod(x)\n","     return x\n","\n","\n","   def get_label(self,edge_index,graph,batch):\n","      edge_number=edge_index.shape[1]\n","      attr_mean=torch.mean(graph,dim=1)\n","      homo_threshold=torch.var(attr_mean)*3\n","      edge_classif=torch.zeros(edge_number)\n","      dic={}\n","      for i in range(len(attr_mean)):\n","        dic[int(i)]=attr_mean[i]\n","\n","      for i in range(len(edge_classif)):\n","        if(abs(dic[int(edge_index[0][i])]-dic[int(edge_index[1][i])])>homo_threshold):\n","          edge_classif[i]=1\n","      return edge_classif"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fW_tbzimddpA"},"outputs":[],"source":["model_heter=learning_hetero().to(device)\n","loss = nn.BCELoss()\n","hopt = torch.optim.Adam(model_heter.parameters(),lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YddeYyKf2Ffq"},"outputs":[],"source":["edge_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w3EtJ6sHsHj7"},"outputs":[],"source":["from torch_geometric.utils.num_nodes import maybe_num_nodes\n","def k_hop_subgraph(\n","    node_idx,\n","    num_hops,\n","    edge_index,\n","    relabel_nodes = False,\n","    num_nodes = None,\n","    flow: str = 'source_to_target',\n","    directed: bool = False,):\n","\n","    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n","    print(num_nodes)\n","\n","    assert flow in ['source_to_target', 'target_to_source']\n","    if flow == 'target_to_source':\n","        row, col = edge_index\n","    else:\n","        col, row = edge_index\n","\n","    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n","    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n","\n","    if isinstance(node_idx, (int, list, tuple)):\n","        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n","    else:\n","        node_idx = node_idx.to(row.device)\n","\n","    subsets = [node_idx]\n","\n","    for _ in range(num_hops):\n","        node_mask.fill_(False)\n","        node_mask[subsets[-1]] = True\n","        torch.index_select(node_mask, 0, row, out=edge_mask)\n","        subsets.append(col[edge_mask])\n","\n","    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n","    inv = inv[:node_idx.numel()]\n","\n","    node_mask.fill_(False)\n","    node_mask[subset] = True\n","\n","    if not directed:\n","        edge_mask = node_mask[row] & node_mask[col]\n","\n","    edge_index = edge_index[:, edge_mask]\n","\n","    if relabel_nodes:\n","        node_idx = row.new_full((num_nodes, ), -1)\n","        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n","        edge_index = node_idx[edge_index]\n","\n","    return subset, edge_index, inv, edge_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UPmgIJNPYxj"},"outputs":[],"source":["causal_model2.eval()\n","predictno_model2.eval()\n","predictco_model2.eval()\n","\n","idex=4\n","tey=t_load[idex].to(device)\n","print(f\"groud label:{tey.y}\")\n","#print(tey)\n","#print(tey.batch)\n","tey.edge_index\n","(xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(tey)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxEbpnaejDdE"},"outputs":[],"source":["\n","ground_heter_c=model_heter.get_label(edge_index,xc,batch)\n","het_c=model_heter(graph=xc,edge_index=edge_index,batch=batch)\n","#ground_heter_o=model_heter.get_label(edge_index,xo,batch)\n","het_o=model_heter(graph=xo,edge_index=edge_index,batch=batch)\n","fin_het=(het_c+het_o)/2\n","loss(fin_het,ground_heter_c.unsqueeze(1))\n","#loss_o=loss(het_c,ground_heter_o.unsqueeze(1))\n","edge_hetero_mask=fin_het.reshape(-1).round()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BcRmNVZlPbqu"},"outputs":[],"source":["torch.var(torch.mean(xo,dim=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ew95MdcNYuMO"},"outputs":[],"source":["torch.mean(xo,dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LJxICK_3YmSp"},"outputs":[],"source":["torch.var(torch.mean(xo,dim=1)*torch.mean(xo,dim=1))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnlUMPyVP8TV"},"outputs":[],"source":["t1=torch.masked_select(tey.edge_index[0],ground_heter_c==1).to(device)\n","t2=torch.masked_select(tey.edge_index[1],ground_heter_c==1).to(device)\n","homo_index=torch.stack([t1,t2]).to(device)\n","edweig_coa=torch.masked_select(edge_weight_o,ground_heter_c==1).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDbBUokLmEHy"},"outputs":[],"source":["len(homo_index[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PW5ntEjbb6No"},"outputs":[],"source":["\n","start = time.time()\n","mask_heter(homo_index,edweig_coa,edge_index,edge_weight_o)\n","end = time.time()\n","print(end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOv5xGJ8WmO9"},"outputs":[],"source":["from torch_geometric.utils import subgraph,k_hop_subgraph\n","def split_graph(graph_x,node_of_graph,edge_index,edge_weight,type_of_graph=True):\n","  if(type_of_graph==True):\n","    select_node_number=int(node_of_graph/3)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    sedge_index,sedge_weight=subgraph(subset=select_node,edge_index=edge_index,edge_attr=edge_weight)\n","\n","    #print(select_node)\n","    return mask_graph(graph_x,select_node),select_node,sedge_index,sedge_weight\n","  else:\n","    select_node_number=int(node_of_graph/2)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    sedge_index,sedge_weight=subgraph(subset=select_node,edge_index=edge_index,edge_attr=edge_weight)\n","    return mask_graph(graph_x,select_node),select_node,sedge_index,sedge_weight\n","node_of_graph=xc.shape[0]\n","#select_node_number=int(node_of_graph/3)\n","#select_node=torch.topk(torch.mean(xo,dim=1),select_node_number)[1]\n","only_cau_part,cau_node,cau_index,cau_weight=split_graph(graph_x=xo,node_of_graph=node_of_graph,edge_index=edge_index,edge_weight=edge_weight_o,type_of_graph=True)\n","#subgraph(subset=select_node,edge_index=homo_index,edge_attr=edweig_coa)\n","#split_graph(graph_x=xc,node_of_graph=node_of_graph,edge_index=homo_index,edge_weight=edweig_coa,type_of_graph=True)\n","\n","def mask_heter(homo_index,edweig,input_index,input_weight):\n","  edge_list2 = []\n","  for i in range(len(homo_index[0])):\n","    edge_list2.append((int(homo_index[0][i]),int(homo_index[1][i]),float(edweig[i])))\n","  homin=set(edge_list2)\n","  l1=[]\n","  l2=[]\n","  lw=[]\n","  for i in range(len(input_index[0])):\n","    if((int(input_index[0][i]),int(input_index[1][i]),float(input_weight[i])) in set(edge_list2)):\n","      l1.append(input_index[0][i])\n","      l2.append(input_index[1][i])\n","      lw.append(input_weight[i])\n","  masked_index=torch.stack([torch.tensor(l1,dtype=torch.long),torch.tensor(l2,dtype=torch.long)]).to(device)\n","  masked_weight=torch.tensor(lw).to(device)\n","  return masked_index,masked_weight\n","mask_heter(homo_index,edweig_coa,cau_index,cau_weight)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qZQ5O7ZVc1D"},"outputs":[],"source":["subset,edge_indexk,inv,mask=k_hop_subgraph(0,1,tey.edge_index)\n","subgraph(subset,tey.edge_index,tey.edge_attr)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ILXK94Q73DXC"},"outputs":[],"source":["#from torch_geometric.utils import subgraph,k_hop_subgraph\n","#import random\n","#from numpy.random import choice\n","causal_model2.eval()\n","predictno_model2.eval()\n","predictco_model2.eval()\n","\n","idex=4\n","tey=t_load[idex].to(device)\n","print(f\"groud label:{tey.y}\")\n","#print(tey)\n","#print(tey.batch)\n","\n","(xo,edge_weight_o),(xc,edge_weight_c),edge_index,batch=causal_model2(tey)\n","ground_heter_c=model_heter.get_label(edge_index,xc,batch)\n","het_c=model_heter(graph=xc,edge_index=edge_index,batch=batch)\n","#ground_heter_o=model_heter.get_label(edge_index,xo,batch)\n","het_o=model_heter(graph=xo,edge_index=edge_index,batch=batch)\n","fin_het=(het_c+het_o)/2\n","loss(fin_het,ground_heter_c.unsqueeze(1))\n","#loss_o=loss(het_c,ground_heter_o.unsqueeze(1))\n","edge_hetero_mask=fin_het.reshape(-1).round()\n","#c_logs, o_logs, co_logs = predict_model(causal=causal,noncausal=noncausal,batch=batch,causal_edge_weight=edge_weight_causal,noncausal_edge_weight=edge_weight_noncausal,edge_index=edge_index)\n","c_logs,co_logs = predictno_model2(causal=xo,noncausal=xc,edge_index=edge_index,causal_edge_weight=edge_weight_o,noncausal_edge_weight=edge_weight_c,batch=batch)\n","o_logs=predictco_model2(causal=xo,edge_index=edge_index,causal_edge_weight=edge_weight_o,batch=batch)\n","#v=uncertainty_mask(causal=causal_part,causal_node=causal_node,batch=batch,data=tey)[1]\n","#olog=predictco_model2.objects_readout_layer(x=v,batch=batch)\n","#olog=predictco_model(causal=causal_part,batch=batch)\n","def split_graph(graph_x,node_of_graph,edge_index,edge_weight,type_of_graph=True):\n","  if(type_of_graph==True):\n","    select_node_number=int(node_of_graph/3)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    sedge_index,sedge_weight=subgraph(subset=select_node,edge_index=edge_index,edge_attr=edge_weight)\n","\n","    #print(select_node)\n","    return mask_graph(graph_x,select_node),select_node,sedge_index,sedge_weight\n","  else:\n","    select_node_number=int(node_of_graph/3*2)\n","    select_node=torch.topk(torch.mean(graph_x,dim=1),select_node_number)[1]\n","    sedge_index,sedge_weight=subgraph(subset=select_node,edge_index=edge_index,edge_attr=edge_weight)\n","    return mask_graph(graph_x,select_node),select_node,sedge_index,sedge_weight\n","\n","def uncertainty_mask_gnerate(graph_x,node_in_graph,edge_index,edge_weight):\n","  all_mask=[]\n","  for i in node_in_graph:\n","    subset,edge_indexk,inv,mask=k_hop_subgraph(node_idx=int(i),num_hops=3,edge_index=edge_index)\n","    #random_mask=random.sample(node_in_graph.tolist(),int(len(node_in_graph)/3))\n","    sedge_index,sedge_weight=subgraph(subset=subset,edge_index=edge_index,edge_attr=edge_weight)\n","    all_mask.append((int(i),mask_graph(graph_x,subset),sedge_index,sedge_weight))\n","  return all_mask\n","node_of_graph=xo.shape[0]\n","g,node,index,weight=split_graph(graph_x=xo,node_of_graph=node_of_graph,edge_index=edge_index,edge_weight=edge_weight_o)\n","o_logs2=predictco_model2(causal=g,edge_index=index,causal_edge_weight=weight,batch=batch)\n","\n","gd=edge_hetero_mask\n","t1=torch.masked_select(edge_index[0],gd==0)\n","t2=torch.masked_select(edge_index[1],gd==0)\n","homo_index=torch.stack([t1,t2])\n","edweig=torch.masked_select(edge_weight_o,gd==0)\n","\n","\n","print(o_logs.max(1)[1])\n","print(o_logs2.max(1)[1])\n","print(len(node))\n","print(len(torch.unique(homo_index)))\n","#k_hop_subgraph(node_idx=int(node[2]),num_hops=1,edge_index=edge_index)\n","#all=uncertainty_mask_gnerate(g,node,homo_index,edweig)\n","#all=uncertainty_mask_gnerate(g,node,index,weight)\n","#for n,i,j,k in all:\n","  #gd=model_heter.get_label(edge_index,xc,batch)\n"," # print(n)\n"," # o_logs=predictco_model2(causal=i,edge_index=j,causal_edge_weight=k,batch=batch)\n"," # print(F.nll_loss(o_logs,tey.y))\n","  #print(o_logs.max(1)[1])\n","#random_mask=random.sample(node_in_graph.tolist(),int(len(node_in_graph)/3))\n","#sedge_index,sedge_weight=subgraph(subset=subset,edge_index=edge_indexk,edge_attr=edge_weight)\n","#all_mask.append((mask_graph(graph_x,subset),sedge_index,sedge_weight))\n","#o_logs2=predictco_model2(causal=g,edge_index=index,causal_edge_weight=weight,batch=batch)\n","#olog=predictco_model2.objects_readout_layer(x=mask_graph(causal_attention,i),batch=batch)\n","\n","#print(o_logs.max(1)[1])\n","#print(o_logs2.max(1)[1])\n","#  print(i)\n","\n","#print(F.nll_loss(olog,tey.y))\n","#plt.hist(all_loss,bins=10)\n","#plt.show()\n","#print(all_logit)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b9MeYWGBFVR"},"outputs":[],"source":["subset,edge_indexk,inv,mask=k_hop_subgraph(node_idx=2169,num_hops=3,edge_index=homo_index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKHhIfA_A7f2"},"outputs":[],"source":["gd=model_heter.get_label(edge_index,g,batch)\n","t1=torch.masked_select(edge_index[0],gd==0)\n","t2=torch.masked_select(edge_index[1],gd==0)\n","edweig=torch.masked_select(edge_weight_o,gd==0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DOYPFuryFd9F"},"outputs":[],"source":["homo_index=torch.stack([t1,t2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ls71X5MW-PF"},"outputs":[],"source":["n,i,j,k=uncertainty_mask_gnerate(g,node,homo_index,edweig)[0]\n","o_logs=predictco_model2(causal=i,edge_index=j,causal_edge_weight=k,batch=batch)\n","print(F.nll_loss(o_logs,tey.y))\n","print(o_logs.max(1)[1])"]},{"cell_type":"markdown","metadata":{"id":"wfakZQYXwxBT"},"source":["def appendloss(batch_size,data,all_causallogit,logit):\n","\n","  if(batch_size==1):\n","    all_causallogit.append(float(logit.view(-1)[data.y]))\n","  else:\n","    for i in range(batch_size):\n","      if(loss.max(1)[1][i]==data.y[i]):\n","        continue\n","\n","      all_causallogit.append(float(logit[i,data.y[i]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9N_yiP6DYXw"},"outputs":[],"source":["homo_index"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"76xBuIu99cm9"},"outputs":[],"source":["np.where(sp_data[0].mean(axis=1)==1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kcB8PgkYF3LQ"},"outputs":[],"source":["import networkx as nx\n","from scipy.spatial.distance import pdist, squareform\n","from pylab import rcParams\n","def plot_superpixels_graph(sp_data, adj_matrix, label, feat_coord, with_edges,real,causal):\n","    Y = squareform(pdist(sp_data[1], 'euclidean'))\n","    x_coord = sp_data[1] #np.flip(dataset.train.sp_data[_][1], 1)\n","    #intensities = sp_data[0].mean(axis=1)\n","    #label = classes[label]\n","    if real:\n","      intensities = sp_data[0].mean(axis=1)\n","    else:\n","      intensities=np.array(causal.mean(axis=1).cpu().detach())\n","      #intensities=np.array([0]*sp_data[0].shape[0])\n","      #intensities[[ 0,  3,  8, 14, 15, 24, 33, 37, 43, 45, 52]]=1\n","\n","\n","\n","\n","    G = nx.from_numpy_array(Y)\n","    pos = dict(zip(range(len(x_coord)), x_coord.tolist()))\n","    rotated_pos = {node: (y,-x) for (node, (x,y)) in pos.items()} # rotate the coords by 90 degree\n","\n","    edge_list = []\n","    for src, dsts in enumerate(compute_edges_list(adj_matrix)[0]):\n","        for dst in dsts:\n","            edge_list.append((src, dst))\n","\n","    nx.draw_networkx_nodes(G, rotated_pos, node_color=intensities, cmap=matplotlib.cm.Reds, node_size=60) #len(intensities))\n","    if with_edges:\n","        nx.draw_networkx_edges(G, rotated_pos, edge_list, alpha=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"265SCDNqt_AH"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"We1l2f0oOs0n"},"outputs":[],"source":["\n","plt.imshow(training_data_01[idex])\n","plt.show()\n","print(\"Label: \",training_label_01[idex])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMHw3DzpYe8B"},"outputs":[],"source":["subset_all=[]\n","for i in range(5):\n","  sub_graph=choice(range(0,graph_nudes),number_of_node,p=F.softmax(tey.x.sum(axis=1)),replace=False)\n","  subset=torch.unique(subgraph(list(sub_graph),tey.edge_index,tey.edge_attr)[0])\n","  subset_all.append(subset)\n","subset_all"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U5ljSMHKTK2c"},"outputs":[],"source":["edge_list2 = []\n","\n","for i in range(len(homo_index[0])):\n","  edge_list2.append((int(homo_index[0][i]),int(homo_index[1][i])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmkM6HRdYB-j"},"outputs":[],"source":["sp_data=data_with_feat_knn.sp_data[idex]\n","adj_matrix=data_with_feat_knn.Adj_matrices[idex]\n","label=data_with_feat_knn[idex][1]\n","feat_coord=data_with_feat_knn.use_feat_for_graph\n","#causal_node=l\n","with_edges=True\n","plt.figure(figsize=(5, 5))\n","real=True\n","Y = squareform(pdist(sp_data[1], 'euclidean'))\n","x_coord = sp_data[1] #np.flip(dataset.train.sp_data[_][1], 1)\n","#intensities = sp_data[0].mean(axis=1)\n","#label = classes[label]\n","if real:\n","  intensities = sp_data[0].mean(axis=1)\n","else:\n","  intensities=np.array(g.mean(axis=1).cpu().detach())\n","  #intensities=np.array([0]*sp_data[0].shape[0])\n","  #intensities[[10]]=1\n","\n","\n","\n","\n","G = nx.from_numpy_array(Y)\n","pos = dict(zip(range(len(x_coord)), x_coord.tolist()))\n","rotated_pos = {node: (y,-x) for (node, (x,y)) in pos.items()} # rotate the coords by 90 degree\n","\n","edge_list = []\n","for src, dsts in enumerate(compute_edges_list(adj_matrix)[0]):\n","    for dst in dsts:\n","        edge_list.append((src, dst))\n","\n","nx.draw_networkx_nodes(G, rotated_pos, node_color=intensities, cmap=matplotlib.cm.Reds, node_size=60) #len(intensities))\n","if with_edges:\n","    nx.draw_networkx_edges(G, rotated_pos, edge_list2, alpha=0.3)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJK8kZM9v4Ct"},"outputs":[],"source":["edge_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYA3EgOmvPGE"},"outputs":[],"source":["edge_list2 = []\n","\n","for i in range(len(homo_index[0])):\n","  edge_list2.append((int(homo_index[0][i]),int(homo_index[1][i])))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MTsNrTNH2-P"},"outputs":[],"source":["\n","sp_data=data_with_feat_knn.sp_data[idex]\n","adj_matrix=data_with_feat_knn.Adj_matrices[idex]\n","label=data_with_feat_knn[idex][1]\n","feat_coord=data_with_feat_knn.use_feat_for_graph\n","#causal_node=l\n","with_edges=True\n","plt.figure(figsize=(5, 5))\n","real=True\n","plot_superpixels_graph(sp_data, adj_matrix, label, feat_coord, with_edges,real,tey.x)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_-FL1ezZXwU"},"outputs":[],"source":["sp_data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zz8k2YNBIE34"},"outputs":[],"source":["plt.figure(figsize=(5, 5))\n","real=True\n","plot_superpixels_graph(sp_data, adj_matrix, label, feat_coord, with_edges,real,causal)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sp9WqPw-8yIR"},"outputs":[],"source":["plt.imshow(training_data_01[idex])\n","plt.show()\n","print(\"Label: \",training_label_01[idex])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Tr1TRhwnOx7"},"outputs":[],"source":["training_data_01[idex].shape"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNbejzLtoVnXjUSO4e2/tjy","gpuClass":"premium","machine_shape":"hm","mount_file_id":"1vxkyFaFaw1QKW0oOQLvkqYt1MyFUa45n","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
